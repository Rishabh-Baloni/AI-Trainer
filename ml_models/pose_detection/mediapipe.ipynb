{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3b881da-dda3-45ec-8ca1-4aed77ffabde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.21-cp312-cp312-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\siddh\\anaconda3\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: absl-py in c:\\users\\siddh\\anaconda3\\lib\\site-packages (from mediapipe) (2.3.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\siddh\\anaconda3\\lib\\site-packages (from mediapipe) (23.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\siddh\\anaconda3\\lib\\site-packages (from mediapipe) (25.9.23)\n",
      "Collecting jax (from mediapipe)\n",
      "  Using cached jax-0.8.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting jaxlib (from mediapipe)\n",
      "  Using cached jaxlib-0.8.0-cp312-cp312-win_amd64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\siddh\\anaconda3\\lib\\site-packages (from mediapipe) (3.9.2)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\siddh\\anaconda3\\lib\\site-packages (from mediapipe) (1.26.4)\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Using cached opencv_contrib_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\siddh\\anaconda3\\lib\\site-packages (from mediapipe) (4.25.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\siddh\\anaconda3\\lib\\site-packages (from mediapipe) (0.5.3)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\siddh\\anaconda3\\lib\\site-packages (from mediapipe) (0.2.1)\n",
      "INFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\siddh\\anaconda3\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Collecting ml_dtypes>=0.5.0 (from jax->mediapipe)\n",
      "  Using cached ml_dtypes-0.5.3-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jax (from mediapipe)\n",
      "  Using cached jax-0.7.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting jaxlib (from mediapipe)\n",
      "  Using cached jaxlib-0.7.2-cp312-cp312-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting jax (from mediapipe)\n",
      "  Using cached jax-0.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting jaxlib (from mediapipe)\n",
      "  Using cached jaxlib-0.7.1-cp312-cp312-win_amd64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: opt_einsum in c:\\users\\siddh\\anaconda3\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.12 in c:\\users\\siddh\\anaconda3\\lib\\site-packages (from jax->mediapipe) (1.13.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\siddh\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\siddh\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\siddh\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\siddh\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\siddh\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\siddh\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\siddh\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\siddh\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "INFO: pip is looking at multiple versions of opencv-contrib-python to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\siddh\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\siddh\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Using cached mediapipe-0.10.21-cp312-cp312-win_amd64.whl (51.0 MB)\n",
      "Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "Using cached jax-0.7.1-py3-none-any.whl (2.8 MB)\n",
      "Using cached jaxlib-0.7.1-cp312-cp312-win_amd64.whl (61.2 MB)\n",
      "Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-win_amd64.whl (46.2 MB)\n",
      "Using cached ml_dtypes-0.5.3-cp312-cp312-win_amd64.whl (208 kB)\n",
      "Installing collected packages: opencv-python, opencv-contrib-python, ml_dtypes, jaxlib, jax, mediapipe\n",
      "  Attempting uninstall: opencv-python\n",
      "    Found existing installation: opencv-python 4.12.0.88\n",
      "    Uninstalling opencv-python-4.12.0.88:\n",
      "      Successfully uninstalled opencv-python-4.12.0.88\n",
      "Successfully installed jax-0.7.1 jaxlib-0.7.1 mediapipe-0.10.21 ml_dtypes-0.5.3 opencv-contrib-python-4.11.0.86 opencv-python-4.11.0.86\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5028048d-f64a-4b32-960b-7011b61195aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "POSE_COLOR = (0, 255, 0)\n",
    "LEFT_HAND_COLOR = (255, 0, 0)\n",
    "RIGHT_HAND_COLOR = (0, 0, 255)\n",
    "\n",
    "UPPER_COLOR = (255, 150, 0)    # ORANGE\n",
    "LOWER_COLOR = (150, 0, 255)    # PURPLE\n",
    "\n",
    "holistic = mp_holistic.Holistic(\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.7,\n",
    "    smooth_landmarks=True\n",
    ")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow(\"Tracker\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"Tracker\", 1920, 1080)  # almost fullscreen but with title bar\n",
    "\n",
    "def body_too_close(landmarks):\n",
    "    if not landmarks:\n",
    "        return True\n",
    "    visible_count = sum(1 for lm in landmarks.landmark if lm.visibility > 0.4)\n",
    "    return visible_count < 15\n",
    "\n",
    "UPPER_BODY_CONNECTIONS = [\n",
    "    (11, 12),  # Shoulders\n",
    "    (11, 13), (13, 15),  # Left arm\n",
    "    (12, 14), (14, 16),  # Right arm\n",
    "    (11, 23), (12, 24)   # Upper torso\n",
    "]\n",
    "\n",
    "LOWER_BODY_CONNECTIONS = [\n",
    "    (23, 24),  # Hips\n",
    "    (23, 25), (25, 27),  # Left leg\n",
    "    (24, 26), (26, 28)   # Right leg\n",
    "]\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = holistic.process(rgb)\n",
    "\n",
    "    if result.pose_landmarks:\n",
    "        lm = result.pose_landmarks.landmark\n",
    "\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame,\n",
    "            result.pose_landmarks,\n",
    "            mp_holistic.POSE_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=POSE_COLOR, thickness=2, circle_radius=3),\n",
    "            mp_drawing.DrawingSpec(color=POSE_COLOR, thickness=2)\n",
    "        )\n",
    "\n",
    "        for a, b in UPPER_BODY_CONNECTIONS:\n",
    "            ax, ay = int(lm[a].x * frame.shape[1]), int(lm[a].y * frame.shape[0])\n",
    "            bx, by = int(lm[b].x * frame.shape[1]), int(lm[b].y * frame.shape[0])\n",
    "            cv2.line(frame, (ax, ay), (bx, by), UPPER_COLOR, 4)\n",
    "\n",
    "        for a, b in LOWER_BODY_CONNECTIONS:\n",
    "            ax, ay = int(lm[a].x * frame.shape[1]), int(lm[a].y * frame.shape[0])\n",
    "            bx, by = int(lm[b].x * frame.shape[1]), int(lm[b].y * frame.shape[0])\n",
    "            cv2.line(frame, (ax, ay), (bx, by), LOWER_COLOR, 4)\n",
    "\n",
    "    if result.left_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame,\n",
    "            result.left_hand_landmarks,\n",
    "            mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=LEFT_HAND_COLOR, thickness=2, circle_radius=3)\n",
    "        )\n",
    "\n",
    "    if result.right_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame,\n",
    "            result.right_hand_landmarks,\n",
    "            mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=RIGHT_HAND_COLOR, thickness=2, circle_radius=3)\n",
    "        )\n",
    "\n",
    "    if body_too_close(result.pose_landmarks):\n",
    "        cv2.putText(frame, \"MOVE AWAY FROM CAMERA\",\n",
    "                    (50, 100), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1.5, (0, 0, 255), 4)\n",
    "\n",
    "    cv2.imshow(\"Tracker\", frame)\n",
    "\n",
    "    if cv2.getWindowProperty(\"Tracker\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key & 0xFF == ord('s'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27640971-2be4-473c-8133-71db2c1322df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9a1d18f",
   "metadata": {},
   "source": [
    "# AI Fitness Trainer - Advanced Pose Detection\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Real-time pose tracking with MediaPipe\n",
    "- Automatic rep counting for squats and pushups\n",
    "- Form scoring (0-100%)\n",
    "- Live feedback on exercise form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7be0533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Pose Detection with Rep Counter and Form Analysis\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Color scheme\n",
    "POSE_COLOR = (0, 255, 0)\n",
    "UPPER_COLOR = (255, 150, 0)\n",
    "LOWER_COLOR = (150, 0, 255)\n",
    "\n",
    "# Exercise state variables\n",
    "exercise_mode = \"squat\"  # Options: squat, pushup\n",
    "rep_count = 0\n",
    "stage = None  # \"up\" or \"down\"\n",
    "form_score = 0\n",
    "feedback_messages = []\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"Calculate angle between three points\"\"\"\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    \n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    \n",
    "    return angle\n",
    "\n",
    "def analyze_squat(landmarks):\n",
    "    \"\"\"Analyze squat form and count reps\"\"\"\n",
    "    global rep_count, stage, form_score, feedback_messages\n",
    "    \n",
    "    # Get landmarks\n",
    "    hip = [landmarks[mp_holistic.PoseLandmark.LEFT_HIP.value].x,\n",
    "           landmarks[mp_holistic.PoseLandmark.LEFT_HIP.value].y]\n",
    "    knee = [landmarks[mp_holistic.PoseLandmark.LEFT_KNEE.value].x,\n",
    "            landmarks[mp_holistic.PoseLandmark.LEFT_KNEE.value].y]\n",
    "    ankle = [landmarks[mp_holistic.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "             landmarks[mp_holistic.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "    shoulder = [landmarks[mp_holistic.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                landmarks[mp_holistic.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "    \n",
    "    # Calculate knee angle\n",
    "    knee_angle = calculate_angle(hip, knee, ankle)\n",
    "    \n",
    "    # Calculate back angle (should be relatively straight)\n",
    "    back_angle = calculate_angle(shoulder, hip, knee)\n",
    "    \n",
    "    feedback_messages = []\n",
    "    score_components = []\n",
    "    \n",
    "    # Check depth\n",
    "    if knee_angle < 90:\n",
    "        if stage != \"down\":\n",
    "            stage = \"down\"\n",
    "        score_components.append(100)  # Good depth\n",
    "    elif knee_angle < 120:\n",
    "        score_components.append(70)\n",
    "        feedback_messages.append(\"Go deeper\")\n",
    "    else:\n",
    "        if stage == \"down\":\n",
    "            stage = \"up\"\n",
    "            rep_count += 1\n",
    "        score_components.append(50)\n",
    "    \n",
    "    # Check back straightness (170-190 degrees is good)\n",
    "    if 160 < back_angle < 200:\n",
    "        score_components.append(100)\n",
    "    else:\n",
    "        score_components.append(50)\n",
    "        feedback_messages.append(\"Keep back straight\")\n",
    "    \n",
    "    # Check knee alignment\n",
    "    knee_x = knee[0]\n",
    "    ankle_x = ankle[0]\n",
    "    if abs(knee_x - ankle_x) < 0.1:  # Knee aligned with ankle\n",
    "        score_components.append(100)\n",
    "    else:\n",
    "        score_components.append(60)\n",
    "        if knee_x > ankle_x:\n",
    "            feedback_messages.append(\"Knees too forward\")\n",
    "    \n",
    "    form_score = int(np.mean(score_components)) if score_components else 0\n",
    "    \n",
    "    return knee_angle, back_angle\n",
    "\n",
    "def analyze_pushup(landmarks):\n",
    "    \"\"\"Analyze pushup form and count reps\"\"\"\n",
    "    global rep_count, stage, form_score, feedback_messages\n",
    "    \n",
    "    # Get landmarks\n",
    "    shoulder = [landmarks[mp_holistic.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                landmarks[mp_holistic.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "    elbow = [landmarks[mp_holistic.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "             landmarks[mp_holistic.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "    wrist = [landmarks[mp_holistic.PoseLandmark.LEFT_WRIST.value].x,\n",
    "             landmarks[mp_holistic.PoseLandmark.LEFT_WRIST.value].y]\n",
    "    hip = [landmarks[mp_holistic.PoseLandmark.LEFT_HIP.value].x,\n",
    "           landmarks[mp_holistic.PoseLandmark.LEFT_HIP.value].y]\n",
    "    knee = [landmarks[mp_holistic.PoseLandmark.LEFT_KNEE.value].x,\n",
    "            landmarks[mp_holistic.PoseLandmark.LEFT_KNEE.value].y]\n",
    "    \n",
    "    # Calculate elbow angle\n",
    "    elbow_angle = calculate_angle(shoulder, elbow, wrist)\n",
    "    \n",
    "    # Calculate body alignment (should be straight)\n",
    "    body_angle = calculate_angle(shoulder, hip, knee)\n",
    "    \n",
    "    feedback_messages = []\n",
    "    score_components = []\n",
    "    \n",
    "    # Check depth (elbow should go below 90 degrees)\n",
    "    if elbow_angle < 90:\n",
    "        if stage != \"down\":\n",
    "            stage = \"down\"\n",
    "        score_components.append(100)\n",
    "    elif elbow_angle < 120:\n",
    "        score_components.append(70)\n",
    "        feedback_messages.append(\"Go lower\")\n",
    "    else:\n",
    "        if stage == \"down\":\n",
    "            stage = \"up\"\n",
    "            rep_count += 1\n",
    "        score_components.append(50)\n",
    "    \n",
    "    # Check body alignment (should be straight, around 170-190 degrees)\n",
    "    if 160 < body_angle < 200:\n",
    "        score_components.append(100)\n",
    "    else:\n",
    "        score_components.append(50)\n",
    "        if body_angle < 160:\n",
    "            feedback_messages.append(\"Hips too low\")\n",
    "        else:\n",
    "            feedback_messages.append(\"Hips too high\")\n",
    "    \n",
    "    form_score = int(np.mean(score_components)) if score_components else 0\n",
    "    \n",
    "    return elbow_angle, body_angle\n",
    "\n",
    "def draw_stats(frame, rep_count, form_score, exercise_mode, feedback_messages):\n",
    "    \"\"\"Draw statistics overlay on frame\"\"\"\n",
    "    # Semi-transparent background for stats\n",
    "    overlay = frame.copy()\n",
    "    cv2.rectangle(overlay, (10, 10), (400, 200), (0, 0, 0), -1)\n",
    "    cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)\n",
    "    \n",
    "    # Exercise mode\n",
    "    cv2.putText(frame, f\"Exercise: {exercise_mode.upper()}\", (20, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    \n",
    "    # Rep counter\n",
    "    cv2.putText(frame, f\"Reps: {rep_count}\", (20, 80),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 255), 3)\n",
    "    \n",
    "    # Form score with color coding\n",
    "    score_color = (0, 255, 0) if form_score > 80 else (0, 165, 255) if form_score > 60 else (0, 0, 255)\n",
    "    cv2.putText(frame, f\"Form: {form_score}%\", (20, 120),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, score_color, 2)\n",
    "    \n",
    "    # Feedback messages\n",
    "    y_offset = 160\n",
    "    for msg in feedback_messages:\n",
    "        cv2.putText(frame, msg, (20, y_offset),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 165, 255), 2)\n",
    "        y_offset += 30\n",
    "    \n",
    "    # Instructions\n",
    "    cv2.putText(frame, \"Press 'q': Squat | 'p': Pushup | 'r': Reset | 's': Stop\",\n",
    "                (10, frame.shape[0] - 20),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "holistic = mp_holistic.Holistic(\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.7,\n",
    "    smooth_landmarks=True\n",
    ")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"AI Fitness Trainer\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"AI Fitness Trainer\", 1280, 720)\n",
    "\n",
    "print(\"üèãÔ∏è AI Fitness Trainer Started!\")\n",
    "print(\"Controls:\")\n",
    "print(\"  'q' - Switch to Squat mode\")\n",
    "print(\"  'p' - Switch to Pushup mode\")\n",
    "print(\"  'r' - Reset rep counter\")\n",
    "print(\"  's' - Stop and exit\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = holistic.process(rgb)\n",
    "    \n",
    "    if result.pose_landmarks:\n",
    "        lm = result.pose_landmarks.landmark\n",
    "        \n",
    "        # Draw pose skeleton\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame,\n",
    "            result.pose_landmarks,\n",
    "            mp_holistic.POSE_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=POSE_COLOR, thickness=2, circle_radius=3),\n",
    "            mp_drawing.DrawingSpec(color=POSE_COLOR, thickness=2)\n",
    "        )\n",
    "        \n",
    "        # Analyze exercise based on mode\n",
    "        if exercise_mode == \"squat\":\n",
    "            analyze_squat(lm)\n",
    "        elif exercise_mode == \"pushup\":\n",
    "            analyze_pushup(lm)\n",
    "    \n",
    "    # Draw stats overlay\n",
    "    draw_stats(frame, rep_count, form_score, exercise_mode, feedback_messages)\n",
    "    \n",
    "    cv2.imshow(\"AI Fitness Trainer\", frame)\n",
    "    \n",
    "    if cv2.getWindowProperty(\"AI Fitness Trainer\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('s'):\n",
    "        break\n",
    "    elif key == ord('q'):\n",
    "        exercise_mode = \"squat\"\n",
    "        rep_count = 0\n",
    "        stage = None\n",
    "        print(\"Switched to SQUAT mode\")\n",
    "    elif key == ord('p'):\n",
    "        exercise_mode = \"pushup\"\n",
    "        rep_count = 0\n",
    "        stage = None\n",
    "        print(\"Switched to PUSHUP mode\")\n",
    "    elif key == ord('r'):\n",
    "        rep_count = 0\n",
    "        stage = None\n",
    "        print(\"Rep counter reset\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"\\n‚úÖ Session Complete!\")\n",
    "print(f\"   Total Reps: {rep_count}\")\n",
    "print(f\"   Final Form Score: {form_score}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
